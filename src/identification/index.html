<!doctype html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <title>Unique Identification of 50,000+ Virtual Reality Users from Head & Hand Motion Data | Berkeley RDI</title>
    <meta name="description" content="With the recent explosive growth of interest and investment in virtual reality (VR) and the so-called 'metaverse,' public attention has rightly shifted toward the unique security and privacy threats that these platforms may pose. While it has long been known that people reveal information about themselves via their motion, the extent to which this makes an individual globally identifiable within virtual reality has not yet been widely understood. In this study, we show that a large number of real VR users (N=55,541) can be uniquely and reliably identified across multiple sessions using just their head and hand motion relative to virtual objects. After training a classification model on 5 minutes of data per person, a user can be uniquely identified amongst the entire pool of 50,000+ with 94.33% accuracy from 100 seconds of motion, and with 73.20% accuracy from just 10 seconds of motion. This work is the first to truly demonstrate the extent to which biomechanics may serve as a unique identifier in VR, on par with widely used biometrics such as facial or fingerprint recognition.">
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.2.0/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha384-gH2yIJqKdNHPEq0n4Mqa/HGKIhSkIHeL5AyhkYV8i59U5AR6csBvApHHNl/vI1Bx" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.1.2/css/all.min.css" integrity="sha512-1sCRPdkRXhBV2PBLUdRb4tMg1w2YPf37qatUFeS7zlBy7jJI8Lf4VHwWfZZfpXtYSLy85pkm9GaYVYMfw5BC1A==" crossorigin="anonymous" referrerpolicy="no-referrer" />
    <link href="metaverse.css" rel="stylesheet">
    <script async src=”https://siteimproveanalytics.com/js/siteanalyze_6294756.js”></script>
  </head>
  <body>
    <nav class="navbar navbar-expand-lg bg-light">
  <div class="container">
    <a class="navbar-brand" href="#" aria-label="Metaverse Research">
    Metaverse Research @
        <img height="30" src="img/rdi-sm.png" alt="RDI Logo">
    </a>
    <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarSupportedContent" aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
      <span class="navbar-toggler-icon"></span>
    </button>
    <div class="collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav ms-auto mb-2 mb-lg-0">
        <li class="nav-item">
          <a class="nav-link" href="https://rdi.berkeley.edu">RDI Home</a>
        </li>
        <li class="nav-item">
          <a class="nav-link" href="https://rdi.berkeley.edu/research">Research Home</a>
        </li>
        <li class="nav-item dropdown">
          <a class="nav-link dropdown-toggle" href="#" role="button" data-bs-toggle="dropdown" aria-expanded="false">
            Metaverse Research
          </a>
          <ul class="dropdown-menu">
            <li><a class="dropdown-item" href="https://rdi.berkeley.edu/metaverse/metadata">MetaData</a></li>
            <li><a class="dropdown-item" href="https://rdi.berkeley.edu/metaverse/metaguard">MetaGuard</a></li>
            <li><a class="dropdown-item" href="https://rdi.berkeley.edu/metaverse/sok">Privacy SoK</a></li>
            <li><a class="dropdown-item" href="https://rdi.berkeley.edu/metaverse/identification">Identification</a></li>
            <li><a class="dropdown-item" href="https://rdi.berkeley.edu/metaverse/profiling">Profiling</a></li>
            <li><a class="dropdown-item" href="https://rdi.berkeley.edu/metaverse/boxrr-23">BOXRR Dataset</a></li>
            <li><a class="dropdown-item" href="https://rdi.berkeley.edu/metaverse/article">S&P Article</a></li>
            <li><a class="dropdown-item" href="https://rdi.berkeley.edu/metaverse/dmm">Motion Masking</a></li>
            <li><hr class="dropdown-divider"></li>
            <li><a class="dropdown-item" href="https://rdi.berkeley.edu/metaverse">View All</a></li>
          </ul>
        </li>
      </ul>
    </div>
  </div>
</nav>

    <div id="carousel" class="carousel slide" data-bs-ride="false">
      <div class="carousel-inner">
        <div class="carousel-item active">
          <div class="carousel-img" style="background-image: url('img/ident.png')"></div>
          <div class="carousel-caption d-none d-md-block">
            <h5 class="text-shadow mt-0 mb-3">Unique Identification of 50,000+ Virtual Reality Users from Head & Hand Motion Data</h5>
            <p><a class="btn btn-primary" href="https://www.usenix.org/conference/usenixsecurity23/presentation/nair-identification" target="_blank"><i class="fa fa-file-lines"></i>&nbsp; Read Paper</a> &nbsp; <a class="btn btn-primary" href="https://github.com/MetaGuard/Identification" target="_blank"><i class="fab fa-github"></i>&nbsp; View Repo</a></p>
          </div>
        </div>
      </div>
    </div>
    <div class="bg-dark text-white py-4">
      <div class="container text-left">
        <div class="row">
          <div class="col-2">
            <p class="mt-0 mb-0">DATA</p>
            <h4>3.96 TB</h4>
          </div>
          <div class="col-2">
            <p class="mt-0 mb-0">USERS</p>
            <h4>55,541</h4>
          </div>
          <div class="col-2">
            <p class="mt-0 mb-0">COUNTRIES</p>
            <h4>40+</h4>
          </div>
          <div class="col-2">
            <p class="mt-0 mb-0">VR DEVICES</p>
            <h4>20+</h4>
          </div>
          <div class="col-2">
            <p class="mt-0 mb-0">REPLAYS</p>
            <h4>2,669,886</h4>
          </div>
          <div class="col-2">
            <p class="mt-0 mb-0">SESSIONS</p>
            <h4>713,013</h4>
          </div>
        </div>
      </div>
    </div>
    <div id="cite" class="bg-primary text-white">
      <div class="container py-5">
<p>Vivek Nair, Wenbo Guo, Justus Mattern, Rui Wang, James F. O'Brien, Louis Rosenberg, and Dawn Song. Unique Identification of 50,000+ Virtual Reality Users from Head & Hand Motion Data. In <i>32nd USENIX Security Symposium (USENIX Security 23)</i>, 2023. https://www.usenix.org/conference/usenixsecurity23/presentation/nair-identification</p>
<label for="motion-data">Motion Data:</label>
<textarea id="motion-data" class="form-control overflow-hidden" rows="7" readonly>
@inproceedings{nairunique2023,
  author = {Vivek Nair and Wenbo Guo and Justus Mattern and Rui Wang and James F. O'Brien and Louis Rosenberg and Dawn Song},
  title = {Unique {Identification} of 50,000 {Virtual} {Reality} {Users} from {Head} and {Hand} {Motion} {Data}},
  booktitle = {32nd USENIX Security Symposium (USENIX Security 23)},
  year = {2023},
  url = {https://www.usenix.org/conference/usenixsecurity23/presentation/nair-identification},
}
</textarea>
      </div>
    </div>
    <div class="py-5 bg-light">
      <div class="container">
        <div class="row align-items-center">
          <div class="col-lg-3">
            <img src="img/shot1.png" class="w-100 rounded" alt="Screenshot 1">
          </div>
          <div class="col-lg-6" style="font-size: 16.5px;">
            <p class="text-secondary">2023 &nbsp;|&nbsp; Vivek Nair &middot; Wenbo Guo &middot; Justus Mattern &middot; Rui Wang &middot; James F. O’Brien &middot; Louis Rosenberg &middot; Dawn Song &nbsp;|&nbsp; https://doi.org/10.48550/arXiv.2302.08927</p>
            <p class="text-justify">With the recent explosive growth of interest and investment in virtual reality (VR) and the so-called "metaverse," public attention has rightly shifted toward the unique security and privacy threats that these platforms may pose. While it has long been known that people reveal information about themselves via their motion, the extent to which this makes an individual globally identifiable within virtual reality has not yet been widely understood. In this study, we show that a large number of real VR users (N=55,541) can be uniquely and reliably identified across multiple sessions using just their head and hand motion relative to virtual objects. After training a classification model on 5 minutes of data per person, a user can be uniquely identified amongst the entire pool of 50,000+ with 94.33% accuracy from 100 seconds of motion, and with 73.20% accuracy from just 10 seconds of motion. This work is the first to truly demonstrate the extent to which biomechanics may serve as a unique identifier in VR, on par with widely used biometrics such as facial or fingerprint recognition.</p>
          </div>
          <div class="col-lg-3">
            <img src="img/shot2.png" class="w-100 rounded" alt="Screenshot 2">
          </div>
        </div>
      </div>
    </div>
    <div>
      <div class="container py-5 text-center">
        <div class="row align-items-center">
          <div class="col-md-4 py-5 py-md-0">
            <img src="img/051-FIG-Motion.svg" class="w-100" alt="Motion Features Figure">
          </div>
          <div class="col-md-8 ps-md-5 text-md-start">
            <h4 class="mb-3">Motion Features</h4>
            <p class="text-justify">Motion data (telemetry) is the primary source of data for user identification and inference in VR. Each frame of telemetry data encodes 3D position and orientation coordinates across each of the three tracked objects. Replacing the three Euler angles with four quaternion elements and summarizing each of these 21 data streams using five summary statistics, namely the minimum, maximum, mean, median, and standard deviation, results in a 105-dimensional motion feature vector.</p>
          </div>
        </div>
        <div class="row align-items-center mt-5">
          <div class="col-md-4 py-5 py-md-0 order-md-last">
            <img src="img/053-FIG-Context.svg" class="w-100" alt="Context Features Figure">
          </div>
          <div class="col-md-8 pe-md-5 text-md-start">
            <h4>Context Features</h4>
            <p class="text-justify">We found 22 features that most accurately characterize movement relative to a single event. These features include, for example, the position, orientation, type, and color of the object, the angle, speed, location, and accuracy of the motion, and the relative distance in both space and time. These context features and 105 motion features corresponding to the one-second intervals before and after the event, totalling 232 dimensions, can be used to identify users with a high degree of accuracy.</p>
          </div>
        </div>
        <div class="row align-items-center mt-5 mb-5">
          <div class="col-md-4 py-5 py-md-0">
            <img src="img/082-FIG-Features.svg" class="w-100" alt="Features Figure">
          </div>
          <div class="col-md-8 ps-md-5 text-md-start">
            <h4>Results</h4>
            <p class="text-justify">After training a classification model on 5 minutes of data per person, a user can be uniquely identified amongst the entire pool of 50,000+ with 94.33% accuracy from 100 seconds of motion, and with 73.20% accuracy from just 10 seconds of motion. Even with a single sample generated from just 2 seconds of telemetry data, the correct user out of 50,000 is identified about 48.45% of the time. Users with 5 or less total replays submitted were harder to identify, while users with 100 or more replays could be identified with over 99.5% accuracy. While static measurements comprise many of the most important features, they account for only 22.9% of the overall performance of the model. Motion features constitute 73.9% of all entropy gain, while contextual features compose the remaining 3.2%.</p>
          </div>
        </div>
      </div>
    </div>
    <div class="bg-dark text-white py-4">
      <div class="container text-center">
        <h5 class="mb-4"><i>Authors:</i></h5>
        <a style="display: inline-block" width="120px" href="https://nair.me">
          <img src="img/vivek.jpg" height="120" class="rounded-circle" alt="Vivek Nair">
          <p style="color: #fff; text-decoration: none; outline: none;">Vivek Nair</p>
        </a>
        <a style="display: inline-block" width="120px" href="https://henrygwb.github.io/">
          <img src="img/wenbo.jpg" height="120" class="rounded-circle" alt="Wenbo Guo">
          <p style="color: #fff; text-decoration: none; outline: none;">Wenbo Guo</p>
        </a>
        <a style="display: inline-block" width="120px" href="https://justusmattern.github.io/">
          <img src="img/justus.png" height="120" class="rounded-circle" alt="Justus Mattern">
          <p style="color: #fff; text-decoration: none; outline: none;">Justus Mattern</p>
        </a>
        <a style="display: inline-block" width="120px" href="https://github.com/Rui-Wang-813">
          <img src="img/rui.jfif" height="120" class="rounded-circle" alt="Rui Wang">
          <p style="color: #fff; text-decoration: none; outline: none;">Rui Wang</p>
        </a>
        <a style="display: inline-block" width="120px" href="http://obrien.berkeley.edu/">
          <img src="img/james.jfif" height="120" class="rounded-circle" alt="James F. O'Brien">
          <p style="color: #fff; text-decoration: none; outline: none;">James F. O'Brien</p>
        </a>
        <a style="display: inline-block" width="120px" href="https://unanimous.ai/staff-item/louis-rosenberg-phd/">
          <img src="img/louis.jfif" height="120" class="rounded-circle" alt="Louis Rosenberg">
          <p style="color: #fff; text-decoration: none; outline: none;">Louis Rosenberg</p>
        </a>
        <a style="display: inline-block" width="120px" href="https://dawnsong.io">
          <img src="img/dawn.jpg" height="120" class="rounded-circle" alt="Dawn Song">
          <p style="color: #fff; text-decoration: none; outline: none;">Dawn Song</p>
        </a>
      </div>
    </div>
    <div class="bg-dark text-white text-center py-2">
  <div class="container">
    <p class="m-0">Copyright &copy;2025 UC Regents &nbsp;|&nbsp; Email us at <a style="color: #ddf" href="mailto:rdi@berkeley.edu">rdi@berkeley.edu</a>.</p>
  </div>
</div>

    <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.2.0/dist/js/bootstrap.bundle.min.js" integrity="sha384-A3rJD856KowSb7dwlZdYEkO39Gagi7vIsF0jrRAoQmDKKtQBHUuLZ9AsSv4jD4Xa" crossorigin="anonymous"></script>
  </body>
</html>
